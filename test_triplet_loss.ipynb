{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random as rd\n",
    "import random\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "'''\n",
    "Author: Ahmed Anu Wahab\n",
    "Date: February 2022\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer_compute(scores_g, scores_i):\n",
    "    '''\n",
    "    Function to calculate Error Rate'''\n",
    "    far = []\n",
    "    frr = []\n",
    "    ini=min(np.concatenate((scores_g, scores_i)))\n",
    "    fin=max(np.concatenate((scores_g, scores_i)))\n",
    "    paso=(fin-ini)/10000\n",
    "    threshold = ini-paso\n",
    "    while threshold < fin+paso:\n",
    "        far.append(len(np.where(scores_i >= threshold)[0])/len(scores_i))\n",
    "        frr.append(len(np.where(scores_g < threshold)[0])/len(scores_g))\n",
    "        threshold = threshold + paso\n",
    "    \n",
    "    gap = abs(np.asarray(far) - np.asarray(frr))\n",
    "    j = np.where(gap==min(gap))[0]\n",
    "    index = j[0]\n",
    "    return 100.0 - (((far[index]+frr[index])/2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(data):\n",
    "    y_pred=loaded_model.predict(data, verbose=0)\n",
    "    out_size = 128\n",
    "    anchor = y_pred[:,:out_size]\n",
    "    return anchor\n",
    "\n",
    "def get_sample(user, test_users, seq_length, features,num_imp):\n",
    "    '''Get genuine user sentence'''\n",
    "    gen_df = pd.read_csv('ml_features/' + user + '.csv')\n",
    "    data = np.zeros(shape=(15, 3, seq_length, features))\n",
    "    G=1\n",
    "    for i in range(15): # get each of the 15 sentences\n",
    "        '''Clean the data by removing duration greater than 5 secs. They are considered outliers'''\n",
    "        A_arr = gen_df[gen_df.sentence_number==i].iloc[:, 3:]\n",
    "        A_arr.drop(A_arr.index[(abs(A_arr.m)>5)|(abs(A_arr.ud)>5)|(abs(A_arr.dd)>5)|(abs(A_arr.uu)>5)], inplace=True)\n",
    "        A_arr = A_arr.values\n",
    "\n",
    "        '''Truncate if number of keystrokes in the sample is greater than the specified sequence length'''\n",
    "        if len(A_arr) >= seq_length:\n",
    "            A = A_arr[:seq_length, :]\n",
    "\n",
    "        '''Pad with zeros if number of keystrokes in the sample is less than the specified sequence length'''\n",
    "        if len(A_arr) < seq_length:\n",
    "            A = np.concatenate([A_arr, np.zeros((seq_length-len(A_arr), features))])\n",
    "\n",
    "        data[i,0,:,:] = A\n",
    "        data[i,1,:,:] = A\n",
    "        data[i,2,:,:] = A\n",
    "\n",
    "    '''Get genuine embeddings'''\n",
    "    genuine_embeddings = get_embeddings([data[:,0,:,:],data[:,1,:,:],data[:,2,:,:]])\n",
    "    '''Select first G embeddings as gallery'''\n",
    "    gallery_embeddings = genuine_embeddings[:G,:]\n",
    "    '''Last 5 as genuine test embeddings'''\n",
    "    genuine_test_embeddings = genuine_embeddings[10:,:]\n",
    "    \n",
    "    # Genuine scores between G gallery samples and 5 genuine test samples\n",
    "    gen_scores = np.mean(euclidean_distances(gallery_embeddings, genuine_test_embeddings), axis = 0)\n",
    "\n",
    "    \n",
    "    '''Get impostor data'''\n",
    "    data = np.zeros(shape=(num_imp, 3, seq_length, features))\n",
    "    imp_users = test_users.copy()\n",
    "    imp_users = imp_users.tolist()\n",
    "    imp_users.remove(user)\n",
    "    for i in range(num_imp):\n",
    "        imp = imp_users[i]\n",
    "        imp_df = pd.read_csv('ml_features/' + imp + '.csv')\n",
    "        A_arr = imp_df[imp_df.sentence_number==11].iloc[:, 3:]\n",
    "        '''Clean the data by removing duration greater than 5 secs. They are considered outliers'''\n",
    "        A_arr.drop(A_arr.index[(abs(A_arr.m)>5)|(abs(A_arr.ud)>5)|(abs(A_arr.dd)>5)|(abs(A_arr.uu)>5)], inplace=True)\n",
    "        A_arr = A_arr.values\n",
    "\n",
    "        '''Truncate if number of keystrokes in the sample is greater than the specified sequence length'''\n",
    "        if len(A_arr) >= seq_length:\n",
    "            A = A_arr[:seq_length, :]\n",
    "\n",
    "        '''Pad with zeros if number of keystrokes in the sample is less than the specified sequence length'''\n",
    "        if len(A_arr) < seq_length:\n",
    "            A = np.concatenate([A_arr, np.zeros((seq_length-len(A_arr), features))])\n",
    "\n",
    "        data[i,0,:,:] = A\n",
    "        data[i,1,:,:] = A\n",
    "        data[i,2,:,:] = A\n",
    "\n",
    "    '''Get impostor embeddings'''\n",
    "    imp_test_embeddings = get_embeddings([data[:,0,:,:],data[:,1,:,:],data[:,2,:,:]])\n",
    "    # Impostor scores between G gallery samples and num_imp test samples\n",
    "    imp_scores = np.mean(euclidean_distances(gallery_embeddings, imp_test_embeddings), axis = 0)\n",
    "    \n",
    "    # Get Error rate\n",
    "    error_rate = eer_compute(gen_scores, imp_scores)\n",
    "    \n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(num_test_users, seq_length, features=5):\n",
    "    test_users = np.load('triplets/test_users.npz')['arr_0']\n",
    "    np.random.shuffle(test_users) # Shuffle the test users\n",
    "    test_users = test_users[:num_test_users]\n",
    "    num_imp = num_test_users-1\n",
    "    EER=[]\n",
    "    for user in test_users:\n",
    "        error_rate = get_sample(user,test_users,seq_length,features,num_imp)\n",
    "        EER.append(error_rate)\n",
    "    return np.mean(EER)\n",
    "\n",
    "def predict_pairs(model):\n",
    "    '''Get genuine test data and predict'''\n",
    "    num_test_users = 1000 # Number of test users\n",
    "    eer = gen_data(num_test_users, 70)\n",
    "    print('AVERAGE EER & ACC for %s Users:' % num_test_users, eer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the trained model\n",
    "'''\n",
    "model_path='triplets/new_model/triplet_model.h5'\n",
    "loaded_model = load_model(model_path, compile=False)\n",
    "\n",
    "\n",
    "'''Call the predict function\n",
    "'''\n",
    "eer=predict_pairs(loaded_model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
